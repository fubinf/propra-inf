name: Maintainer-ProgramChecker-MultiContainer

on:
  schedule:
    # Run every Sunday at 04:30 UTC (offset from single-container version)
    - cron: '30 4 * * 0'
  workflow_dispatch:  # Allow manual triggering
    inputs:
      max_workers:
        description: 'Max program checker workers (default 4)'
        required: false
        default: '4'

# Multi-container isolation strategy: each taskgroup runs in an independent container

jobs:
  setup:
    runs-on: ubuntu-latest
    container: debian:12
    outputs:
      taskgroups: ${{ steps.extract.outputs.taskgroups }}
    env:
      SDRL_PROGCHECK_MAX_WORKERS: ${{ github.event.inputs.max_workers || '4' }}

    steps:
    - name: Install system dependencies for Debian 12
      run: |
        apt-get update
        apt-get install -y \
          bash \
          git \
          curl \
          ca-certificates \
          jq \
          nodejs \
          npm \
          python3.11 \
          python3.11-venv
        ln -s /usr/bin/python3.11 /usr/bin/python

    - name: Checkout propra-inf repository
      uses: actions/checkout@v4
      with:
        submodules: recursive
        token: ${{ secrets.SUBMODULE_TOKEN }}

    - name: Checkout sedrila repository
      uses: actions/checkout@v4
      with:
        repository: fubinf/sedrila
        path: sedrila

    - name: Create and activate Python virtual environment
      shell: bash
      run: |
        python -m venv /tmp/sedrila_venv
        source /tmp/sedrila_venv/bin/activate
        python -m pip install --upgrade pip
        # Install sedrila dependencies from pyproject.toml
        cd sedrila && pip install -e . && cd ..

    - name: Collect and display metadata
      shell: bash
      run: |
        source /tmp/sedrila_venv/bin/activate
        python sedrila/py/sedrila.py maintainer --log ERROR --collect -o /tmp/metadata.json 2>/dev/null || echo '{"taskgroups": {}}' > /tmp/metadata.json
        echo "Collected metadata:"
        cat /tmp/metadata.json
        echo ""
        echo "=== Taskgroups and Language Requirements ==="
        jq -r '.taskgroups | to_entries[] | "\(.key): lang: \(.value.lang | @json)"' /tmp/metadata.json || echo "No taskgroups specified"
        echo ""
        echo "=== Task Dependencies ==="
        jq -r '.taskgroups[] | .tasks | to_entries[] | "\(.key): deps: \(.value.deps | @json)"' /tmp/metadata.json || echo "No task dependencies specified"
        echo ""

    - name: Extract taskgroups for matrix
      id: extract
      shell: bash
      run: |
        TASKGROUPS=$(jq -r '.taskgroups | keys | @json' /tmp/metadata.json 2>/dev/null)
        echo "taskgroups=${TASKGROUPS}" >> $GITHUB_OUTPUT
        echo "Extracted taskgroups: $TASKGROUPS"

  program-check-per-taskgroup:
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      matrix:
        taskgroup: ${{ fromJson(needs.setup.outputs.taskgroups) }}

    container: debian:12

    steps:
    - name: "[Container: ${{ matrix.taskgroup }}] Install minimal base dependencies"
      shell: bash
      run: |
        echo "=== Installing minimal base dependencies ==="

        apt-get update
        apt-get install -y \
          bash \
          curl \
          git \
          ca-certificates \
          jq \
          nodejs \
          npm \
          python3.11 \
          python3.11-venv
        ln -s /usr/bin/python3.11 /usr/bin/python

        echo "Minimal base dependencies installed"
        echo "Node.js version: $(node --version)"
        echo "npm version: $(npm --version)"

    - name: "[Container: ${{ matrix.taskgroup }}] Checkout repositories"
      uses: actions/checkout@v4
      with:
        submodules: recursive
        token: ${{ secrets.SUBMODULE_TOKEN }}

    - name: "[Container: ${{ matrix.taskgroup }}] Checkout sedrila"
      uses: actions/checkout@v4
      with:
        repository: fubinf/sedrila
        path: sedrila

    - name: "[Container: ${{ matrix.taskgroup }}] Setup Python venv for sedrila"
      shell: bash
      run: |
        echo "=== Setting up Python environment in container ==="
        python3 -m venv /tmp/sedrila_venv
        source /tmp/sedrila_venv/bin/activate
        python -m pip install --upgrade pip
        cd sedrila && pip install -e . && cd ..
        echo "Python venv ready"

    - name: "[Container: ${{ matrix.taskgroup }}] Get taskgroup metadata"
      shell: bash
      run: |
        # Download metadata from setup job
        echo "=== Getting metadata for ${{ matrix.taskgroup }} ==="
        mkdir -p /tmp/artifacts
        # In real scenario, we'd download the artifact; for now, we regenerate
        source /tmp/sedrila_venv/bin/activate
        python sedrila/py/sedrila.py maintainer --log ERROR --collect -o /tmp/metadata.json 2>/dev/null
        echo "Metadata collected"

    - name: "[Container: ${{ matrix.taskgroup }}] Extract lang and deps for this taskgroup"
      shell: bash
      run: |
        echo "=== Extracting lang and deps for taskgroup: ${{ matrix.taskgroup }} ==="

        TASKGROUP="${{ matrix.taskgroup }}"
        LANG_CMDS=$(jq -r ".taskgroups[\"$TASKGROUP\"].lang | @csv" /tmp/metadata.json 2>/dev/null)
        DEPS_CMDS=$(jq -r ".taskgroups[\"$TASKGROUP\"].deps | @csv" /tmp/metadata.json 2>/dev/null)

        echo "Lang commands: $LANG_CMDS"
        echo "Deps commands: $DEPS_CMDS"

        # Save for next steps
        echo "$LANG_CMDS" > /tmp/lang_cmds.txt
        echo "$DEPS_CMDS" > /tmp/deps_cmds.txt

    - name: "[Container: ${{ matrix.taskgroup }}] Install language runtime"
      shell: bash
      run: |
        echo "=== Installing language runtime for ${{ matrix.taskgroup }} ==="

        LANG_CMDS=$(cat /tmp/lang_cmds.txt)

        if [ -z "$LANG_CMDS" ] || [ "$LANG_CMDS" = "null" ] || [ "$LANG_CMDS" = "" ]; then
          echo "[SKIP] No lang commands for this taskgroup"
        else
          echo "Executing lang commands: $LANG_CMDS"
          # Parse CSV-like format
          echo "$LANG_CMDS" | tr ',' '\n' | while read -r cmd; do
            cmd=$(echo "$cmd" | sed 's/^"//;s/"$//;s/\\//g')
            if [ ! -z "$cmd" ]; then
              echo "Running: $cmd"
              eval "$cmd" || echo "Warning: Lang command failed but continuing"
            fi
          done
        fi

        echo "Language runtime installation complete"

    - name: "[Container: ${{ matrix.taskgroup }}] Install task dependencies"
      shell: bash
      run: |
        echo "=== Installing dependencies for ${{ matrix.taskgroup }} ==="

        source /tmp/sedrila_venv/bin/activate

        DEPS_CMDS=$(cat /tmp/deps_cmds.txt)

        if [ -z "$DEPS_CMDS" ] || [ "$DEPS_CMDS" = "null" ] || [ "$DEPS_CMDS" = "" ]; then
          echo "[SKIP] No deps commands for this taskgroup"
        else
          echo "Executing deps commands: $DEPS_CMDS"
          # Parse CSV-like format
          echo "$DEPS_CMDS" | tr ',' '\n' | while read -r cmd; do
            cmd=$(echo "$cmd" | sed 's/^"//;s/"$//;s/\\//g')
            if [ ! -z "$cmd" ]; then
              echo "Running: $cmd"
              eval "$cmd" || echo "Warning: Deps command failed but continuing"
            fi
          done
        fi

        echo "Dependencies installation complete"

    - name: "[Container: ${{ matrix.taskgroup }}] Verify environment after installation"
      shell: bash
      run: |
        echo "=== Environment after language/dependency installation ==="
        echo ""
        echo "Current PATH:"
        echo "$PATH"
        echo ""
        echo "Installed packages:"
        apt list --installed 2>/dev/null | grep -E "python|go|node|gcc|git|java" | head -20 || true
        echo ""
        echo "Tools in /usr/bin:"
        ls -1 /usr/bin | grep -E "python|go|node|npm|gcc|git|java" || echo "  (none found)"
        echo ""
        echo "Tools in /usr/local/bin:"
        ls -1 /usr/local/bin 2>/dev/null | head -10 || echo "  (directory not found or empty)"

    - name: "[Container: ${{ matrix.taskgroup }}] Create isolation base"
      shell: bash
      run: |
        echo "=== Creating isolation directory ==="
        mkdir -p /tmp/sedrila_taskgroups
        echo "/tmp/sedrila_taskgroups" > /tmp/isolation_base.txt

        # In multi-container, each container has its own /usr/local
        # No need for additional isolation since we are already isolated
        echo "Isolation base: /tmp/sedrila_taskgroups"

    - name: "[Container: ${{ matrix.taskgroup }}] Setup taskgroup paths"
      shell: bash
      run: |
        echo "=== Setup taskgroup paths ==="
        # Multi-container approach: each container is already isolated
        # So we pass empty taskgroup_paths; programchecker.py will use default container PATH
        echo '{}' > /tmp/taskgroup_paths.json
        echo "Using container-native isolation (no taskgroup_paths needed)"

    - name: "[Container: ${{ matrix.taskgroup }}] Run program checks for this taskgroup"
      shell: bash
      env:
        SDRL_TASKGROUP: ${{ matrix.taskgroup }}
      run: |
        echo "=== Running program checks for taskgroup: ${{ matrix.taskgroup }} ==="

        source /tmp/sedrila_venv/bin/activate

        python sedrila/py/sedrila.py maintainer \
          --check-programs \
          --batch \
          --taskgroup-paths /tmp/taskgroup_paths.json \
          /tmp/progcheck_${{ matrix.taskgroup }}
      continue-on-error: true

    - name: "[Container: ${{ matrix.taskgroup }}] Process program check report"
      if: always()
      shell: bash
      run: |
        TASKGROUP="${{ matrix.taskgroup }}"
        REPORT_MD="/tmp/progcheck_${{ matrix.taskgroup }}_i/program_test_report.md"

        if [ -f "$REPORT_MD" ]; then
          echo "=== Report for taskgroup: $TASKGROUP ==="
          head -50 "$REPORT_MD"
        else
          echo "No report generated for $TASKGROUP"
        fi

    - name: "[Container: ${{ matrix.taskgroup }}] Upload taskgroup report for aggregation"
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: program-check-report-${{ matrix.taskgroup }}
        path: /tmp/progcheck_${{ matrix.taskgroup }}_i/program_test_report.md
        retention-days: 1

  aggregate-results:
    needs: program-check-per-taskgroup
    runs-on: ubuntu-latest
    if: always()
    steps:
    - name: Download all reports
      uses: actions/download-artifact@v4
      with:
        path: /tmp/all_reports

    - name: Aggregate and merge reports (using ProgramChecker format)
      run: |
        python3 << 'PYTHON_EOF'
        import os
        import re
        from pathlib import Path
        from datetime import datetime
        from dataclasses import dataclass

        @dataclass
        class TestResult:
            """Simplified test result structure."""
            program_name: str
            taskgroup: str
            typ: str  # 'manual' or 'regex'
            success: bool
            skipped: bool
            execution_time: float = 0.0
            error_message: str = ""
            manual_reason: str = ""
            files: str = ""

        def parse_test_results_from_report(report_content, taskgroup):
            """Parse test results from a markdown report."""
            results = []

            # Parse Summary section to get stats
            summary_match = re.search(r'- \*\*Total programs:\*\* (\d+)', report_content)
            if not summary_match:
                return results

            # Parse Passed Tests table
            passed_section = re.search(r'## Passed Tests\n\n(.*?)(?=\n## |\Z)', report_content, re.DOTALL)
            if passed_section:
                table_rows = re.findall(r'\| `([^`]+)` \| (.*?) \| ([\d.]+)s \|', passed_section.group(1))
                for program_name, files, exec_time in table_rows:
                    results.append(TestResult(
                        program_name=program_name,
                        taskgroup=taskgroup,
                        typ='regex',
                        success=True,
                        skipped=False,
                        execution_time=float(exec_time),
                        files=files
                    ))

            # Parse Skipped Tests table
            skipped_section = re.search(r'## Skipped Tests.*?\n\n(.*?)(?=\n## |\Z)', report_content, re.DOTALL)
            if skipped_section:
                table_rows = re.findall(r'\| `([^`]+)` \| (.*?) \| (.*?) \|', skipped_section.group(1))
                for program_name, files, reason in table_rows:
                    results.append(TestResult(
                        program_name=program_name,
                        taskgroup=taskgroup,
                        typ='manual',
                        success=False,
                        skipped=True,
                        manual_reason=reason,
                        files=files
                    ))

            # Parse Failed Tests table
            failed_section = re.search(r'## Failed Tests\n\n(.*?)(?=\n### |\n## |\Z)', report_content, re.DOTALL)
            if failed_section:
                table_rows = re.findall(r'\| `([^`]+)` \| (.*?) \| (.*?) \|', failed_section.group(1))
                for program_name, files, error in table_rows:
                    results.append(TestResult(
                        program_name=program_name,
                        taskgroup=taskgroup,
                        typ='regex',
                        success=False,
                        skipped=False,
                        error_message=error,
                        files=files
                    ))

            return results

        def generate_unified_report(all_results):
            """Generate report in programchecker.py format."""
            report_lines = []

            # Header (same as programchecker.py)
            report_lines.append("# Program Test Report\n")
            report_lines.append(f"\n**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            report_lines.append("**Run parameters:** max_workers = 4\n\n")

            # Statistics
            total = len(all_results)
            passed = sum(1 for r in all_results if r.success)
            failed = sum(1 for r in all_results if not r.success and not r.skipped)
            skipped = sum(1 for r in all_results if r.skipped)

            pass_rate = (passed / total * 100) if total > 0 else 0.0
            fail_rate = (failed / total * 100) if total > 0 else 0.0
            skip_rate = (skipped / total * 100) if total > 0 else 0.0

            # Summary section
            report_lines.append("## Summary\n\n")
            report_lines.append(f"- **Total programs:** {total}\n")
            report_lines.append(f"- **Passed:** {passed} ({pass_rate:.1f}%)\n")
            report_lines.append(f"- **Failed:** {failed} ({fail_rate:.1f}%)\n")
            report_lines.append(f"- **Skipped (manual test):** {skipped} ({skip_rate:.1f}%)\n\n")

            # Failed Tests section
            if failed > 0:
                report_lines.append("## Failed Tests\n\n")
                report_lines.append("| Test | Files | Error |\n")
                report_lines.append("|------|-------|-------|\n")
                for r in all_results:
                    if not r.success and not r.skipped:
                        error_msg = r.error_message.replace('\n', ' ').replace('|', '\\|')[:100]
                        report_lines.append(f"| `{r.program_name}` | {r.files} | {error_msg} |\n")
                report_lines.append("\n")

                report_lines.append("### Failed Tests Detail\n\n")
                for r in all_results:
                    if not r.success and not r.skipped:
                        mode_label = "[REGEX]"
                        report_lines.append(f"#### {r.program_name} {mode_label}\n\n")
                        report_lines.append(f"- **Error:** {r.error_message}\n")
                        report_lines.append(f"- **Taskgroup:** {r.taskgroup}\n\n")

            # Skipped Tests section
            if skipped > 0:
                report_lines.append("## Skipped Tests (Manual Testing Required)\n\n")
                report_lines.append("| Test | Files | Reason |\n")
                report_lines.append("|------|-------|--------|\n")
                for r in all_results:
                    if r.skipped:
                        reason = r.manual_reason.replace('\n', ' ').replace('|', '\\|')
                        report_lines.append(f"| `{r.program_name}` | {r.files} | {reason} |\n")
                report_lines.append("\n")

            # Passed Tests section
            if passed > 0:
                report_lines.append("## Passed Tests\n\n")
                report_lines.append("| Test | Files | Execution Time |\n")
                report_lines.append("|------|-------|----------------|\n")
                for r in all_results:
                    if r.success:
                        report_lines.append(f"| `{r.program_name}` | {r.files} | {r.execution_time:.2f}s |\n")
                report_lines.append("\n")

            return ''.join(report_lines)

        def main():
            """Main aggregation logic."""
            reports_dir = Path('/tmp/all_reports')
            all_results = []

            # Collect all test results from individual reports
            for report_dir in sorted(reports_dir.glob('program-check-report-*')):
                taskgroup = report_dir.name.replace('program-check-report-', '')
                report_file = report_dir / 'program_test_report.md'

                if report_file.exists():
                    try:
                        content = report_file.read_text()
                        results = parse_test_results_from_report(content, taskgroup)
                        all_results.extend(results)
                        print(f"✓ Parsed {len(results)} tests from taskgroup: {taskgroup}")
                    except Exception as e:
                        print(f"✗ Error parsing {report_file}: {e}")

            if not all_results:
                print("✗ No test results found!")
                return

            # Generate unified report
            unified_report = generate_unified_report(all_results)
            output_path = Path('/tmp/merged_report.md')
            output_path.write_text(unified_report)

            # Statistics
            passed = sum(1 for r in all_results if r.success)
            failed = sum(1 for r in all_results if not r.success and not r.skipped)
            skipped = sum(1 for r in all_results if r.skipped)
            total = len(all_results)

            print(f"\n✓ Unified report generated: {output_path}")
            print(f"  Total Programs: {total}")
            print(f"  Passed: {passed} ({passed/total*100:.1f}%)")
            print(f"  Failed: {failed} ({failed/total*100:.1f}%)")
            print(f"  Skipped: {skipped} ({skipped/total*100:.1f}%)")

        main()
        PYTHON_EOF

    - name: Publish merged report to summary
      run: |
        cat /tmp/merged_report.md >> $GITHUB_STEP_SUMMARY

    - name: Upload merged report
      uses: actions/upload-artifact@v4
      with:
        name: program-check-merged-report
        path: /tmp/merged_report.md
        retention-days: 90

    - name: Clean up intermediate taskgroup reports
      if: always()
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        echo "Deleting intermediate taskgroup reports..."
        # Get all artifacts for this run
        ARTIFACTS=$(gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts --jq '.artifacts[] | select(.name | startswith("program-check-report-")) | .id')

        if [ -z "$ARTIFACTS" ]; then
          echo "No intermediate artifacts to delete"
          exit 0
        fi

        for artifact_id in $ARTIFACTS; do
          echo "Deleting artifact ID: $artifact_id"
          gh api repos/${{ github.repository }}/actions/artifacts/$artifact_id -X DELETE
        done
        echo "Cleanup completed"
